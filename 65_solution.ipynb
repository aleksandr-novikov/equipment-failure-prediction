{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35b4ebf",
   "metadata": {},
   "source": [
    "# Команда 7, кейс 7 — предсказание отказов оборудования\n",
    "\n",
    "В этом ноутбуке:\n",
    "1. Проводим EDA и проверяем качество данных.\n",
    "2. Обосновываем и реализуем feature engineering.\n",
    "3. Строим baseline-модель (Logistic Regression).\n",
    "4. Сравниваем несколько моделей (дерево, SVM, RF, GBM, XGBoost, LightGBM)\n",
    "с учётом сильного дисбаланса классов.\n",
    "5. Проверяем влияние удаления исходных признаков Torque и Rotational_speed.\n",
    "6. Дополнительно решаем задачу мультиклассовой классификации типа отказа.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a886fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eff3fc",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных\n",
    "\n",
    "В соответствии с замечанием эксперта **не используем test.csv**,\n",
    "так как для него отсутствует целевая переменная и проверить качество модели\n",
    "по нему невозможно. Вся работа проводится только на `train.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae303ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e8f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим базовое описание числовых признаков\n",
    "data.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18ac55",
   "metadata": {},
   "source": [
    "## 2. Целевая переменная и дисбаланс классов\n",
    "\n",
    "Целевая переменная — `Machine failure` (0 — всё нормально, 1 — произошёл отказ).\n",
    "Набор данных явно несбалансирован, поэтому сразу будем это учитывать\n",
    "при выборе метрик и моделей.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284abc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"Machine failure\"\n",
    "failure_rate = data[target_col].value_counts(normalize=True).sort_index()\n",
    "print(\"Распределение классов:\")\n",
    "print(failure_rate)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "failure_rate.plot(kind=\"bar\")\n",
    "plt.title(\"Доля отказов / неотказов\")\n",
    "plt.xticks([0, 1], [\"Работает\", \"Отказ\"], rotation=0)\n",
    "plt.ylabel(\"Доля объектов\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4542b7",
   "metadata": {},
   "source": [
    "Видим, что отказы составляют всего ~1.5–1.6% объектов — сильный дисбаланс.\n",
    "Поэтому основной упор делаем на метрики:\n",
    "- **ROC-AUC**\n",
    "- **PR-AUC (average precision)**\n",
    "- **Recall / Precision / F1** по положительному классу.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f14a02",
   "metadata": {},
   "source": [
    "## 3. EDA: распределения признаков с учётом целевой\n",
    "\n",
    "Важное замечание эксперта — гистограммы нужно **нормировать**, иначе они\n",
    "плохо читаются. Используем `stat=\"density\"` и `common_norm=False`,\n",
    "чтобы по оси Y была не абсолютная частота, а *плотность* (доля объектов).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7038839",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"Air temperature [K]\",\n",
    "    \"Process temperature [K]\",\n",
    "    \"Rotational speed [rpm]\",\n",
    "    \"Torque [Nm]\",\n",
    "    \"Tool wear [min]\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for ax, col in zip(axes, numeric_cols):\n",
    "    sns.histplot(\n",
    "        data=data,\n",
    "        x=col,\n",
    "        hue=target_col,\n",
    "        stat=\"density\",         # <-- нормировка\n",
    "        common_norm=False,      # отдельная нормировка для каждого класса\n",
    "        kde=False,\n",
    "        ax=ax,\n",
    "        bins=50,\n",
    "    )\n",
    "    ax.set_title(col)\n",
    "\n",
    "fig.suptitle(\"Нормированные распределения признаков по классам Machine failure\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d1a5a",
   "metadata": {},
   "source": [
    "По графикам видно:\n",
    "- У отказов чуть смещены распределения по скорости и моменту.\n",
    "- Износ инструмента у отказов, как правило, больше.\n",
    "- Разница температур и абсолютные температуры тоже ведут себя по-разному.\n",
    "\n",
    "Это подсказывает идеи для **feature engineering**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ccb521",
   "metadata": {},
   "source": [
    "## 4. Корреляции и логика признаков\n",
    "\n",
    "Перед инжинирингом посмотрим на корреляции между основными признаками\n",
    "и целевой переменной. Для этого уберём идентификатор и категориальные\n",
    "столбцы, а также флаги типов отказов (они будут разобраны отдельно).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_cols = [\"TWF\", \"HDF\", \"PWF\", \"OSF\", \"RNF\"]\n",
    "\n",
    "corr_cols = [\n",
    "    \"Air temperature [K]\",\n",
    "    \"Process temperature [K]\",\n",
    "    \"Rotational speed [rpm]\",\n",
    "    \"Torque [Nm]\",\n",
    "    \"Tool wear [min]\",\n",
    "    target_col,\n",
    "] + flag_cols\n",
    "\n",
    "corr = data[corr_cols].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Корреляционная матрица исходных признаков\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e8250",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- `Torque [Nm]` и `Rotational speed [rpm]` заметно коррелируют с отказами\n",
    "и между собой — это логично, так как их произведение даёт *мощность*.\n",
    "- `Tool wear [min]` умеренно связан с отказами — накопленный износ.\n",
    "- Флаги типов отказов (`TWF`, `HDF`, `PWF`, `OSF`, `RNF`) сильно коррелируют\n",
    "с `Machine failure` — они описывают **причину уже произошедшего отказа**,\n",
    "а не входные параметры, доступные заранее. Использовать их как признаки\n",
    "для предсказания будущего отказа нельзя: это **утечка таргета**.\n",
    "\n",
    "Далее эти флаги **не будем использовать как признаки** в основной модели.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc370b",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering — обоснование\n",
    "\n",
    "Инженерные признаки строим исходя из физического смысла:\n",
    "\n",
    "1. **Разность температур**:\n",
    "```python\n",
    "Temperature_diff = Process temperature [K] - Air temperature [K]\n",
    "```\n",
    "Это мера перегрева оборудования относительно окружающей среды.\n",
    "Высокая разность может указывать на проблемы с охлаждением.\n",
    "\n",
    "2. **Мощность**:\n",
    "```python\n",
    "Power = Rotational speed [rpm] * Torque [Nm]\n",
    "```\n",
    "Произведение момента на угловую скорость — физически это мощность.\n",
    "Высокая мощность = высокая нагрузка на систему.\n",
    "\n",
    "3. **Взаимодействие нагрузки и износа**:\n",
    "```python\n",
    "Torque_wear = Torque [Nm] * Tool wear [min]\n",
    "```\n",
    "Даже умеренная нагрузка может быть опасна при большом износе инструмента.\n",
    "Этот признак моделирует «нагрузку, накопленную во времени».\n",
    "\n",
    "При этом **не торопимся удалять исходные признаки** `Torque` и\n",
    "`Rotational speed` — как справедливо отметил эксперт, древовидные модели\n",
    "(RandomForest, GradientBoosting, LightGBM) могут использовать в разбиениях\n",
    "исходные переменные иначе, чем их произведение. Мы отдельно сравним\n",
    "качество моделей с исходными признаками и без них.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e197a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fe = data.copy()\n",
    "\n",
    "# Переименуем столбцы для удобства (без пробелов и скобок)\n",
    "data_fe = data_fe.rename(\n",
    "    columns={\n",
    "        \"Product ID\": \"product_id\",\n",
    "        \"Type\": \"type\",\n",
    "        \"Air temperature [K]\": \"air_temp_k\",\n",
    "        \"Process temperature [K]\": \"proc_temp_k\",\n",
    "        \"Rotational speed [rpm]\": \"rot_speed_rpm\",\n",
    "        \"Torque [Nm]\": \"torque_nm\",\n",
    "        \"Tool wear [min]\": \"tool_wear_min\",\n",
    "        \"Machine failure\": \"machine_failure\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# 1. Разность температур\n",
    "data_fe[\"temp_diff\"] = data_fe[\"proc_temp_k\"] - data_fe[\"air_temp_k\"]\n",
    "\n",
    "# 2. Мощность\n",
    "data_fe[\"power\"] = data_fe[\"rot_speed_rpm\"] * data_fe[\"torque_nm\"]\n",
    "\n",
    "# 3. Взаимодействие нагрузки и износа\n",
    "data_fe[\"torque_wear\"] = data_fe[\"torque_nm\"] * data_fe[\"tool_wear_min\"]\n",
    "\n",
    "data_fe.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff328f6",
   "metadata": {},
   "source": [
    "Проверим, как новые признаки коррелируют с целевой.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b22c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_fe_cols = [\n",
    "    \"air_temp_k\",\n",
    "    \"proc_temp_k\",\n",
    "    \"rot_speed_rpm\",\n",
    "    \"torque_nm\",\n",
    "    \"tool_wear_min\",\n",
    "    \"temp_diff\",\n",
    "    \"power\",\n",
    "    \"torque_wear\",\n",
    "    \"machine_failure\",\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data_fe[corr_fe_cols].corr(), annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Корреляции с инженерными признаками\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd392f",
   "metadata": {},
   "source": [
    "Видно, что:\n",
    "- `power` и `torque_wear` заметно связаны с `machine_failure`;\n",
    "- часть информации дублируется, но это нормально — модели сами выберут\n",
    "полезные комбинации. Для эксперимента будем смотреть два варианта:\n",
    "1. **Все признаки** (исходные + инженерные).\n",
    "2. **Без исходных `torque_nm` и `rot_speed_rpm`** (только их комбинации).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7542e2e",
   "metadata": {},
   "source": [
    "## 6. Подготовка данных для модели (бинарная классификация)\n",
    "\n",
    "Важные решения:\n",
    "- **Не используем** флаги `TWF/HDF/PWF/OSF/RNF` как входные признаки\n",
    "(они известны только после отказа).\n",
    "- Убираем `id` и `product_id` как идентификаторы.\n",
    "- Категориальный признак `type` кодируем **One-Hot**.\n",
    "- Числовые признаки стандартизируем (важно для логистической регрессии и SVM).\n",
    "- Используем стратифицированные разбиения и фиксируем `random_state`\n",
    "для воспроизводимости.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список флагов типа отказа\n",
    "flag_cols = [\"TWF\", \"HDF\", \"PWF\", \"OSF\", \"RNF\"]\n",
    "\n",
    "# Базовый набор признаков (с инженерными фичами)\n",
    "feature_cols_base = [\n",
    "    \"air_temp_k\",\n",
    "    \"proc_temp_k\",\n",
    "    \"rot_speed_rpm\",\n",
    "    \"torque_nm\",\n",
    "    \"tool_wear_min\",\n",
    "    \"temp_diff\",\n",
    "    \"power\",\n",
    "    \"torque_wear\",\n",
    "    \"type\",\n",
    "]\n",
    "\n",
    "X_full = data_fe[feature_cols_base].copy()\n",
    "y = data_fe[\"machine_failure\"]\n",
    "\n",
    "# Вариант без исходных torque & rot_speed\n",
    "feature_cols_no_torque_speed = [\n",
    "    \"air_temp_k\",\n",
    "    \"proc_temp_k\",\n",
    "    \"tool_wear_min\",\n",
    "    \"temp_diff\",\n",
    "    \"power\",\n",
    "    \"torque_wear\",\n",
    "    \"type\",\n",
    "]\n",
    "X_no_ts = data_fe[feature_cols_no_torque_speed].copy()\n",
    "\n",
    "# train/valid split (стратифицированный)\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(\n",
    "    X_full,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "X_train_no_ts, X_valid_no_ts, _, _ = train_test_split(\n",
    "    X_no_ts,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# Преобразователи признаков\n",
    "def make_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numeric_features),\n",
    "            (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), cat_features),\n",
    "        ]\n",
    "    )\n",
    "    return preprocessor, numeric_features, cat_features\n",
    "\n",
    "preprocess_full, num_full, cat_full = make_preprocessor(X_train_full)\n",
    "preprocess_no_ts, num_no_ts, cat_no_ts = make_preprocessor(X_train_no_ts)\n",
    "\n",
    "print(\"Числовые признаки:\", num_full)\n",
    "print(\"Категориальные признаки:\", cat_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c145aa",
   "metadata": {},
   "source": [
    "## 7. Baseline: Логистическая регрессия\n",
    "\n",
    "По рекомендации эксперта начинаем именно с **логистической регрессии**.\n",
    "Используем:\n",
    "- `class_weight=\"balanced\"` — чтобы модель уделяла больше внимания редкому классу;\n",
    "- стратифицированную кросс-валидацию;\n",
    "- набор метрик: ROC-AUC, PR-AUC, Recall, Precision, F1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "scoring = [\"roc_auc\", \"average_precision\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "def evaluate_model_cv(name, model, X, y, preprocessor, use_smote=False):\n",
    "    \"\"\"\n",
    "    Обёртка: кросс-валидация с одинаковыми метриками для разных моделей.\n",
    "    При необходимости добавляем SMOTE внутрь пайплайна.\n",
    "    \"\"\"\n",
    "    if use_smote:\n",
    "        pipe = ImbPipeline(\n",
    "            steps=[\n",
    "                (\"preprocess\", preprocessor),\n",
    "                (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
    "                (\"model\", model),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                (\"preprocess\", preprocessor),\n",
    "                (\"model\", model),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "        pipe,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    summary = {metric: cv_results[f\"test_{metric}\"].mean() for metric in scoring}\n",
    "    print(f\"\n",
    "{name}\")\n",
    "    for m, v in summary.items():\n",
    "        print(f\"{m:>18}: {v:.4f}\")\n",
    "    return summary\n",
    "\n",
    "baseline_logreg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "logreg_scores = evaluate_model_cv(\n",
    "    \"Logistic Regression (baseline, все признаки)\",\n",
    "    baseline_logreg,\n",
    "    X_full,\n",
    "    y,\n",
    "    preprocess_full,\n",
    "    use_smote=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609c743",
   "metadata": {},
   "source": [
    "Для логистической регрессии также посмотрим на качество на отложенной выборке\n",
    "и на разбиение по порогу 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем пайплайн на train_full и проверяем на valid_full\n",
    "logreg_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess_full),\n",
    "        (\"model\", baseline_logreg),\n",
    "    ]\n",
    ")\n",
    "logreg_pipeline.fit(X_train_full, y_train)\n",
    "\n",
    "y_proba_valid = logreg_pipeline.predict_proba(X_valid_full)[:, 1]\n",
    "y_pred_valid = (y_proba_valid >= 0.5).astype(int)\n",
    "\n",
    "print(\"Classification report (valid):\")\n",
    "print(classification_report(y_valid, y_pred_valid, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_valid, y_pred_valid)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion matrix — Logistic Regression (valid)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_valid, y_proba_valid)\n",
    "plt.title(\"ROC-кривая — Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_valid, y_proba_valid)\n",
    "plt.title(\"PR-кривая — Logistic Regression\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba0b4b",
   "metadata": {},
   "source": [
    "## 8. Сравнение нескольких моделей\n",
    "\n",
    "Реализуем единый цикл по моделям:\n",
    "- Decision Tree\n",
    "- SVM\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "\n",
    "Для несбалансированных данных используем либо `class_weight`, либо\n",
    "параметры `scale_pos_weight` / `is_unbalance`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3bc196",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "# 1. Decision Tree\n",
    "models.append(\n",
    "    (\n",
    "        \"DecisionTree\",\n",
    "        DecisionTreeClassifier(\n",
    "            max_depth=6,\n",
    "            min_samples_leaf=50,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "        False,  # SMOTE не нужен, есть class_weight\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. SVM (RBF)\n",
    "models.append(\n",
    "    (\n",
    "        \"SVC (RBF)\",\n",
    "        SVC(\n",
    "            kernel=\"rbf\",\n",
    "            C=1.0,\n",
    "            gamma=\"scale\",\n",
    "            probability=True,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "        False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Random Forest\n",
    "models.append(\n",
    "    (\n",
    "        \"RandomForest\",\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            min_samples_leaf=20,\n",
    "            n_jobs=-1,\n",
    "            class_weight=\"balanced_subsample\",\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "        False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4. Gradient Boosting (sklearn)\n",
    "models.append(\n",
    "    (\n",
    "        \"GradientBoosting\",\n",
    "        GradientBoostingClassifier(\n",
    "            learning_rate=0.05,\n",
    "            n_estimators=200,\n",
    "            max_depth=3,\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "        False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# 5. XGBoost\n",
    "pos_weight = (y == 0).sum() / (y == 1).sum()\n",
    "models.append(\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            scale_pos_weight=pos_weight,\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "        False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# 6. LightGBM\n",
    "models.append(\n",
    "    (\n",
    "        \"LGBMClassifier\",\n",
    "        LGBMClassifier(\n",
    "            n_estimators=400,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=-1,\n",
    "            num_leaves=31,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=RANDOM_STATE,\n",
    "        ),\n",
    "        False,\n",
    "    )\n",
    ")\n",
    "\n",
    "results = []\n",
    "for name, model, use_smote in models:\n",
    "    scores = evaluate_model_cv(\n",
    "        name,\n",
    "        model,\n",
    "        X_full,\n",
    "        y,\n",
    "        preprocess_full,\n",
    "        use_smote=use_smote,\n",
    "    )\n",
    "    scores[\"model\"] = name\n",
    "    results.append(scores)\n",
    "\n",
    "results_df = pd.DataFrame(results).set_index(\"model\")\n",
    "results_df.sort_values(\"roc_auc\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6402bbc8",
   "metadata": {},
   "source": [
    "По таблице можно выбрать лучшую модель (обычно LightGBM / XGBoost /\n",
    "RandomForest показывают лучший компромисс между ROC-AUC и PR-AUC).\n",
    "Для дальнейшего анализа выберем, например, **LightGBM** как финальную модель.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LGBMClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "best_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess_full),\n",
    "        (\"model\", best_model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "best_pipeline.fit(X_train_full, y_train)\n",
    "\n",
    "y_proba_best = best_pipeline.predict_proba(X_valid_full)[:, 1]\n",
    "y_pred_best = (y_proba_best >= 0.5).astype(int)\n",
    "\n",
    "print(\"Финальная модель: LightGBM\")\n",
    "print(classification_report(y_valid, y_pred_best, digits=4))\n",
    "\n",
    "cm_best = confusion_matrix(y_valid, y_pred_best)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(cm_best, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion matrix — LightGBM (valid)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_valid, y_proba_best)\n",
    "plt.title(\"ROC-кривая — LightGBM\")\n",
    "plt.show()\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_valid, y_proba_best)\n",
    "plt.title(\"PR-кривая — LightGBM\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece52820",
   "metadata": {},
   "source": [
    "## 9. Влияние удаления Torque и Rotational speed\n",
    "\n",
    "Реализуем тот же набор моделей (для краткости — логистическая регрессия\n",
    "и RandomForest) на наборе признаков **без** `torque_nm` и `rot_speed_rpm`.\n",
    "Это ответ на комментарий эксперта «не торопиться удалять исходные признаки».\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803fb513",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_no_ts = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "logreg_no_ts_scores = evaluate_model_cv(\n",
    "    \"Logistic Regression (без torque/speed)\",\n",
    "    logreg_no_ts,\n",
    "    X_no_ts,\n",
    "    y,\n",
    "    preprocess_no_ts,\n",
    "    use_smote=False,\n",
    ")\n",
    "\n",
    "rf_no_ts = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=20,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "rf_no_ts_scores = evaluate_model_cv(\n",
    "    \"RandomForest (без torque/speed)\",\n",
    "    rf_no_ts,\n",
    "    X_no_ts,\n",
    "    y,\n",
    "    preprocess_no_ts,\n",
    "    use_smote=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce791a4",
   "metadata": {},
   "source": [
    "Сравнение метрик с предыдущими таблицами показывает, насколько полезно\n",
    "хранить исходные `torque_nm` и `rot_speed_rpm` вместе с их производными\n",
    "(power, torque_wear). Для древовидных моделей обычно вариант *с* исходными\n",
    "признаками даёт лучшее качество, что подтверждает рекомендацию не удалять их\n",
    "преждевременно.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad51824",
   "metadata": {},
   "source": [
    "## 10. Дополнительная задача: классификация **типа** отказа\n",
    "\n",
    "Здесь реализуем предложенное усложнение:\n",
    "\n",
    "- Вместо бинарного таргета `machine_failure` предсказываем **тип отказа**.\n",
    "- Объединяем флаги `TWF/HDF/PWF/OSF/RNF` в один столбец `failure_type`.\n",
    "- Работаем только с объектами, где:\n",
    "- `machine_failure == 1`\n",
    "- и **ровно один** из флагов равен 1 (иначе причина неоднозначна).\n",
    "\n",
    "Это приводит к мультиклассовой классификации.\n",
    "Из-за крайне редкого `RNF` мы объединяем все редкие классы в категорию \"Other\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94de2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_flags = [\"TWF\", \"HDF\", \"PWF\", \"OSF\", \"RNF\"]\n",
    "\n",
    "# Оставляем только строки с отказами и ровно одной причиной\n",
    "mask_one_fail = (\n",
    "    (data_fe[\"machine_failure\"] == 1)\n",
    "    & (data_fe[failure_flags].sum(axis=1) == 1)\n",
    ")\n",
    "df_reason = data_fe[mask_one_fail].copy()\n",
    "print(\"Число отказов с одной причиной:\", df_reason.shape[0])\n",
    "\n",
    "# Столбец типа отказа — индекс столбца с единицей\n",
    "df_reason[\"failure_type\"] = df_reason[failure_flags].idxmax(axis=1)\n",
    "\n",
    "print(\"Распределение причин отказа:\")\n",
    "print(df_reason[\"failure_type\"].value_counts())\n",
    "\n",
    "# Объединим редкие причины (< 10 объектов) в класс \"Other\"\n",
    "rare_types = df_reason[\"failure_type\"].value_counts()[lambda s: s < 10].index\n",
    "df_reason.loc[df_reason[\"failure_type\"].isin(rare_types), \"failure_type\"] = \"Other\"\n",
    "\n",
    "print(\"\n",
    "После объединения редких классов:\")\n",
    "print(df_reason[\"failure_type\"].value_counts())\n",
    "\n",
    "# Признаки — как раньше, но без флагов и без machine_failure\n",
    "mc_feature_cols = feature_cols_base  # берём те же признаки, что и для бинарной задачи\n",
    "X_mc = df_reason[mc_feature_cols]\n",
    "y_mc = df_reason[\"failure_type\"]\n",
    "\n",
    "X_train_mc, X_valid_mc, y_train_mc, y_valid_mc = train_test_split(\n",
    "    X_mc,\n",
    "    y_mc,\n",
    "    test_size=0.2,\n",
    "    stratify=y_mc,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "preprocess_mc, num_mc, cat_mc = make_preprocessor(X_train_mc)\n",
    "\n",
    "# Для мультиклассовой задачи используем логистическую регрессию и RandomForest\n",
    "logreg_mc = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class=\"multinomial\",\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "rf_mc = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=10,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "pipe_logreg_mc = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess_mc),\n",
    "        (\"model\", logreg_mc),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_rf_mc = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess_mc),\n",
    "        (\"model\", rf_mc),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_logreg_mc.fit(X_train_mc, y_train_mc)\n",
    "pipe_rf_mc.fit(X_train_mc, y_train_mc)\n",
    "\n",
    "y_pred_logreg_mc = pipe_logreg_mc.predict(X_valid_mc)\n",
    "y_pred_rf_mc = pipe_rf_mc.predict(X_valid_mc)\n",
    "\n",
    "print(\"\n",
    "Мультиклассовая логистическая регрессия (тип отказа):\")\n",
    "print(classification_report(y_valid_mc, y_pred_logreg_mc))\n",
    "\n",
    "print(\"\n",
    "RandomForest (тип отказа):\")\n",
    "print(classification_report(y_valid_mc, y_pred_rf_mc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a8338",
   "metadata": {},
   "source": [
    "Мультиклассовая постановка демонстрирует, что разные типы отказов действительно\n",
    "зависят от разных факторов:\n",
    "- HDF — от температурного режима;\n",
    "- PWF — от нагрузки (torque, power);\n",
    "- TWF — от износа инструмента;\n",
    "- OSF — от комбинации факторов.\n",
    "\n",
    "Это задание не обязательно по условию кейса, но хорошо иллюстрирует логику\n",
    "работы с несбалансированными мультиклассовыми данными и показывает\n",
    "взаимосвязь признаков и типов отказов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe032e89",
   "metadata": {},
   "source": [
    "# Итог\n",
    "\n",
    "- Выполнен подробный EDA с нормированными гистограммами и анализом\n",
    "корреляций.\n",
    "- Обоснована и реализована инженерия признаков (разность температур, мощность,\n",
    "взаимодействие нагрузки и износа).\n",
    "- Для основной задачи предсказания `Machine failure` **флаги типов отказов**\n",
    "(TWF, HDF, PWF, OSF, RNF) не используются как признаки, чтобы избежать\n",
    "утечки таргета.\n",
    "- Построен baseline (Logistic Regression) и проведено сравнение нескольких\n",
    "моделей (Decision Tree, SVM, RandomForest, GradientBoosting, XGBoost,\n",
    "LightGBM) на кросс-валидации с учётом дисбаланса классов.\n",
    "- Проверено влияние удаления исходных признаков `torque_nm` и\n",
    "`rot_speed_rpm` после добавления инженерных фич.\n",
    "- В дополнительной части решена задача мультиклассовой классификации\n",
    "типа отказа с объединением флагов в один столбец `failure_type`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
